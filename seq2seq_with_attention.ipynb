{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarise- seq2seq with attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXvVY6zf1VJfBZTyk/d82Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Astha32/News-Headline-Generation/blob/main/seq2seq_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtzBSmGe_tl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RERSHfKp9a4k",
        "outputId": "ec786935-4718-4927-d86d-fe127c66a189"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe9QovJkLk33"
      },
      "source": [
        "## Preparing Data:\n",
        "\n",
        "The dataset prepared from raw BBC headlines data is used as input for the model.\n",
        "\n",
        "The data is preprocessed using torchtext and tokenisation is carried out using spaCy. The training and validation iterators are created using BucketIterator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B58glmszfDNl"
      },
      "source": [
        "SEED = 23\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfEBgLckfNxx"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFbZIEGfQZA"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrSo6xz-fW0d"
      },
      "source": [
        "TXT = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zw4flFcWUZ9"
      },
      "source": [
        "fields = [('Cleaned_Article', TXT), ('Cleaned_Headline', TXT)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "814DXtkxwalJ"
      },
      "source": [
        "vocab_data = data.TabularDataset(\n",
        "                            path = '/content/BBCNewsDataComplete.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8_uUrf9faFn"
      },
      "source": [
        "train_data= data.TabularDataset(\n",
        "                            path = '/content/BBCnews_trainset.csv',\n",
        "                            format = 'csv', \n",
        "                            fields = fields)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGZZEz1gIo2"
      },
      "source": [
        "val_data = data.TabularDataset(\n",
        "                            path = '/content/BBCnews_testset.csv',\n",
        "                            format = 'csv', \n",
        "                            fields = fields)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRFDDSCn0mVR"
      },
      "source": [
        "import torchtext.vocab "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgRd73GRepFr"
      },
      "source": [
        "TXT.build_vocab(vocab_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMP7u-ClXex"
      },
      "source": [
        "# Build vocabulary and use pretrained fasttext embeddings (observation: model performance gone down)\n",
        "# TXT.build_vocab(vocab_data,\n",
        "#                 max_size=25000,\n",
        "#                 min_freq=2,\n",
        "#                 vectors='fasttext.simple.300d',\n",
        "#                 unk_init=torch.Tensor.normal_)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "thP7Dk2Cz512",
        "outputId": "1f173641-d6e4-404e-940e-da0b26b16fc3"
      },
      "source": [
        "dta = [len(i.Cleaned_Headline) for i in train_data]\n",
        "plt.hist(dta, bins=np.arange(min(dta), max(dta)+1))\n",
        "len(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOl0lEQVR4nO3dXYycV33H8e+POBAILw5ka7m26UbCoooqkUSrEBqE2rigvAnnAlBQC1Zkyb1Iq1AqUcNNhdSLIFWEIlWRrJhiWt7SQBQLIkqUBLVcJLBOQt4MYkkTbNeJF0gCKaVt4N+LPakmxvbuzs56PIfvRxrNOec5M8//0Wp/++yZZ2ZSVUiS+vKScRcgSRo9w12SOmS4S1KHDHdJ6pDhLkkdWjPuAgDOPvvsmp6eHncZkjRR9u3b96OqmjrWtlMi3Kenp5mdnR13GZI0UZI8cbxtLstIUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHTol3qEqnqumdXx13CSPz+PVXjLsEnUSeuUtSh5YU7kkeT/JQkgeSzLax1ya5I8n32/1ZbTxJPplkLsmDSS5YzQOQJP265Zy5/2FVnVdVM62/E7izqjYDd7Y+wGXA5nbbAdw4qmIlSUuzkmWZrcCe1t4DXDUw/placA+wNsn6FexHkrRMSw33Ar6eZF+SHW1sXVUdbu0ngXWtvQE4MPDYg23sRZLsSDKbZHZ+fn6I0iVJx7PUq2XeWlWHkvwWcEeS7w5urKpKUsvZcVXtAnYBzMzMLOuxkqQTW9KZe1UdavdHgFuBC4GnXlhuafdH2vRDwKaBh29sY5Kkk2TRcE9yZpJXvdAG3gE8DOwFtrVp24DbWnsv8P521cxFwLMDyzeSpJNgKcsy64Bbk7ww/3NV9bUk3wZuTrIdeAJ4T5t/O3A5MAf8HLhm5FVLkk5o0XCvqseANx1j/MfAlmOMF3DtSKqTJA3Fd6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH/A5VrYqevntUmkSeuUtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aMnhnuS0JPcn+Urrn5Pk3iRzSb6Y5KVt/GWtP9e2T69O6ZKk41nOmft1wP6B/seAG6rqDcDTwPY2vh14uo3f0OZJkk6iJYV7ko3AFcBNrR/gEuCWNmUPcFVrb2192vYtbb4k6SRZ6pn7J4APAb9q/dcBz1TV861/ENjQ2huAAwBt+7Nt/osk2ZFkNsns/Pz8kOVLko5l0XBPciVwpKr2jXLHVbWrqmaqamZqamqUTy1Jv/HWLGHOxcA7k1wOnAG8Gvg7YG2SNe3sfCNwqM0/BGwCDiZZA7wG+PHIK5ckHdeiZ+5V9eGq2lhV08DVwF1V9cfA3cC72rRtwG2tvbf1advvqqoaadWSpBNayXXufwV8MMkcC2vqu9v4buB1bfyDwM6VlShJWq6lLMv8v6r6BvCN1n4MuPAYc34BvHsEtUmShuQ7VCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdWjTck5yR5FtJvpPkkSQfbePnJLk3yVySLyZ5aRt/WevPte3Tq3sIkqSjLeXM/b+BS6rqTcB5wKVJLgI+BtxQVW8Anga2t/nbgafb+A1tniTpJFo03GvBc617ersVcAlwSxvfA1zV2ltbn7Z9S5KMrGJJ0qKWtOae5LQkDwBHgDuAHwDPVNXzbcpBYENrbwAOALTtzwKvO8Zz7kgym2R2fn5+ZUchSXqRJYV7Vf2yqs4DNgIXAr+70h1X1a6qmqmqmampqZU+nSRpwLKulqmqZ4C7gbcAa5OsaZs2Aoda+xCwCaBtfw3w45FUK0lakqVcLTOVZG1rvxx4O7CfhZB/V5u2Dbittfe2Pm37XVVVoyxaknRiaxafwnpgT5LTWPhjcHNVfSXJo8AXkvwNcD+wu83fDfxjkjngJ8DVq1C3JOkEFg33qnoQOP8Y44+xsP5+9PgvgHePpDpJ0lB8h6okdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR1aNNyTbEpyd5JHkzyS5Lo2/tokdyT5frs/q40nySeTzCV5MMkFq30QkqQXW8qZ+/PAX1bVucBFwLVJzgV2AndW1WbgztYHuAzY3G47gBtHXrUk6YQWDfeqOlxV97X2z4D9wAZgK7CnTdsDXNXaW4HP1IJ7gLVJ1o+8cknScS1rzT3JNHA+cC+wrqoOt01PAutaewNwYOBhB9vY0c+1I8lsktn5+fllli1JOpElh3uSVwJfAj5QVT8d3FZVBdRydlxVu6pqpqpmpqamlvNQSdIilhTuSU5nIdg/W1VfbsNPvbDc0u6PtPFDwKaBh29sY5Kkk2QpV8sE2A3sr6qPD2zaC2xr7W3AbQPj729XzVwEPDuwfCNJOgnWLGHOxcD7gIeSPNDGPgJcD9ycZDvwBPCetu124HJgDvg5cM1IK5YkLWrRcK+qbwI5zuYtx5hfwLUrrEuStAK+Q1WSOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4tGu5JPpXkSJKHB8Zem+SOJN9v92e18ST5ZJK5JA8muWA1i5ckHdtSztw/DVx61NhO4M6q2gzc2foAlwGb220HcONoypQkLcei4V5V/wr85KjhrcCe1t4DXDUw/placA+wNsn6URUrSVqaNUM+bl1VHW7tJ4F1rb0BODAw72AbO8xRkuxg4eye17/+9UOWIWmppnd+ddwljMzj118x7hJOeSt+QbWqCqghHrerqmaqamZqamqlZUiSBgwb7k+9sNzS7o+08UPApoF5G9uYJOkkGjbc9wLbWnsbcNvA+PvbVTMXAc8OLN9Ikk6SRdfck3we+APg7CQHgb8GrgduTrIdeAJ4T5t+O3A5MAf8HLhmFWqWJC1i0XCvqvceZ9OWY8wt4NqVFiVJWhnfoSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHVo2C/r0Cro6csUJI2XZ+6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShyb+O1T93lFJ+nWrcuae5NIk30syl2TnauxDknR8Iw/3JKcBfw9cBpwLvDfJuaPejyTp+FZjWeZCYK6qHgNI8gVgK/DoKuxL0m+gnpZjH7/+ilV53tUI9w3AgYH+QeDNR09KsgPY0brPJfnekPs7G/jRkI891Xgsp55ejgM8llNSPraiY/md420Y2wuqVbUL2LXS50kyW1UzIyhp7DyWU08vxwEey6lqtY5lNV5QPQRsGuhvbGOSpJNkNcL928DmJOckeSlwNbB3FfYjSTqOkS/LVNXzSf4M+BfgNOBTVfXIqPczYMVLO6cQj+XU08txgMdyqlqVY0lVrcbzSpLGyI8fkKQOGe6S1KGJDfckm5LcneTRJI8kuW7cNQ0ryRlJvpXkO+1YPjrumlYiyWlJ7k/ylXHXshJJHk/yUJIHksyOu56VSLI2yS1Jvptkf5K3jLumYSR5Y/t5vHD7aZIPjLuuYST5i/b7/nCSzyc5Y6TPP6lr7knWA+ur6r4krwL2AVdV1cS9EzZJgDOr6rkkpwPfBK6rqnvGXNpQknwQmAFeXVVXjrueYSV5HJipqol/s0ySPcC/VdVN7Sq2V1TVM+OuayXaR50cAt5cVU+Mu57lSLKBhd/zc6vqv5LcDNxeVZ8e1T4m9sy9qg5X1X2t/TNgPwvvjp04teC51j293Sbyr26SjcAVwE3jrkULkrwGeBuwG6Cq/mfSg73ZAvxg0oJ9wBrg5UnWAK8A/mOUTz6x4T4oyTRwPnDveCsZXlvKeAA4AtxRVZN6LJ8APgT8atyFjEABX0+yr31cxqQ6B5gH/qEtl92U5MxxFzUCVwOfH3cRw6iqQ8DfAj8EDgPPVtXXR7mPiQ/3JK8EvgR8oKp+Ou56hlVVv6yq81h4R++FSX5v3DUtV5IrgSNVtW/ctYzIW6vqAhY+4fTaJG8bd0FDWgNcANxYVecD/wlM9Edxt6WldwL/PO5ahpHkLBY+UPEc4LeBM5P8ySj3MdHh3tanvwR8tqq+PO56RqH9u3w3cOm4axnCxcA721r1F4BLkvzTeEsaXju7oqqOALey8Imnk+ggcHDgv8FbWAj7SXYZcF9VPTXuQob0R8C/V9V8Vf0v8GXg90e5g4kN9/Yi5G5gf1V9fNz1rESSqSRrW/vlwNuB7463quWrqg9X1caqmmbhX+a7qmqkZyMnS5Iz2wv1tCWMdwAPj7eq4VTVk8CBJG9sQ1uY/I/gfi8TuiTT/BC4KMkrWpZtYeF1w5GZ5K/Zuxh4H/BQW6sG+EhV3T7Gmoa1HtjTXv1/CXBzVU30ZYQdWAfcuvB7xxrgc1X1tfGWtCJ/Dny2LWc8Blwz5nqG1v7Yvh3403HXMqyqujfJLcB9wPPA/Yz4Ywgm9lJISdLxTeyyjCTp+Ax3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KH/A9YJklXrqNRoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1L6jeLeljas"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akVhhfvFlmzn"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_iterator = BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x : len(x.Cleaned_Article),\n",
        "    device = device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a51jzxs_jXH"
      },
      "source": [
        "valid_iterator = BucketIterator(\n",
        "    val_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x : len(x.Cleaned_Article),\n",
        "    device = device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5oW9U6eNWXK"
      },
      "source": [
        "## Seq2Seq Model with Attention:\n",
        "\n",
        "\n",
        "\n",
        "*   Encoder: It is a 2 layer bidirectional GRU. The input article is embedded using the embedding layer and then dropout layer is applied. The obtained embedded vectors are passed into RNN which returns outputs(top layer hidden state) and hidden states of each layer.\n",
        "*   Attention layer: The previous hidden state of decoder and the encoder outputs are supplied as input to obtain attention vector that represents which words in the source sentence should be paid the most attention in order to predict the next word to decode. The weighted source vector is created using the attention vector.\n",
        "\n",
        "\n",
        "\n",
        "*   Decoder: It is a 1 layer unidirectional GRU. The previous hidden state of decoder, weighted source vector and the embedded input word are supplied as input to the RNN to obtain the next predicted word in the target headline.\n",
        "\n",
        "\n",
        "\n",
        "*   Seq2Seq: It encapsulates the encoder and decoder and will provide a way to interface with each. It receives the input sentence(news article) and passes it to encoder to produce the context vectors. The target headline and the encoder outputs are then passed to the decoder to produce the predicted headline.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv-YSEeglohf"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim, emb_dim, shared_embedding, num_layers=2, dropout=0.0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = shared_embedding\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim,  num_layers=2, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src_len = [batch size]\n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
        "        \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "                \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMGy5t9qlyKC"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention= [batch size, src len]\n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XDdR-el1cG"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, shared_embedding, emb_dim, enc_hid_dim, \n",
        "                 dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = shared_embedding\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5fqNDNVl66e"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, output_dim, embedding_size, vocab_size, enc_hidden_size, dec_hidden_size,\n",
        "                 src_pad_idx, enc_dropout, dec_dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        \n",
        "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
        "\n",
        "        self.encoder = Encoder(enc_hidden_size, dec_hidden_size, embedding_size, self.embedding, num_layers=2, dropout=enc_dropout)\n",
        "        \n",
        "        self.decoder = Decoder(output_dim, self.embedding, embedding_size, enc_hidden_size, dec_hidden_size, dropout=dec_dropout,attention=self.attention )\n",
        "        \n",
        "        self.device = device\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def create_mask(self, src):\n",
        "      mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "      return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, trg_len, teacher_forcing_ratio = 0.0):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio = probability to use teacher forcing\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        # trg_len = trg.shape[0]\n",
        "        target_len = max(trg_len)\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        # outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        outputs = torch.zeros(target_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        mask = self.create_mask(src)\n",
        "        \n",
        "        for t in range(1, target_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cajNau6LRLew"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtXMOy-el-zi"
      },
      "source": [
        "\n",
        "Embedding_size = 256\n",
        "Vocab_size = len(TXT.vocab)\n",
        "Enc_hidden_size = 512\n",
        "Dec_hidden_size = 512\n",
        "Enc_dropout = 0.5\n",
        "Dec_dropout = 0.5\n",
        "pad_idx = TXT.vocab.stoi[TXT.pad_token]\n",
        "model = Seq2Seq(Vocab_size, Embedding_size, Vocab_size, Enc_hidden_size, Dec_hidden_size,\n",
        "                 pad_idx, Enc_dropout, Dec_dropout, device).to(device)\n",
        "\n",
        "# pretrained_embeddings = TXT.vocab.vectors\n",
        "# model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TXT.vocab.stoi[TXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(Embedding_size)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(Embedding_size)\n",
        "model.embedding.weight.requires_grad = True\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "difvZSAfmA6X",
        "outputId": "289d497c-553f-4dd2-ae21-5e60ca17ad03"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (embedding): Embedding(21696, 256)\n",
              "  (attention): Attention(\n",
              "    (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "    (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(21696, 256)\n",
              "    (rnn): GRU(256, 512, num_layers=2, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(21696, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=21696, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Q5GZ_VmDOG",
        "outputId": "e7591655-2757-4961-87f2-f41fadbe5e69"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 55,613,120 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01YxN6kjmF8r"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTZPg21dmH3g"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo3aBF9vmJj1"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.Cleaned_Article\n",
        "        trg, trg_len = batch.Cleaned_Headline\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg, trg_len)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yteBEpdLmMas"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.Cleaned_Article\n",
        "            trg, trg_len = batch.Cleaned_Headline\n",
        "\n",
        "            output = model(src, src_len, trg, trg_len, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAl6zPpkmO4g"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FrkK8EHmQjg",
        "outputId": "635fdb69-4b3e-4386-c58f-0f0c7acc62c2"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "torch.save(model.state_dict(), 'seq2seq-model.pt')\n",
        "    "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 35s\n",
            "\tTrain Loss: 8.276\n",
            "Epoch: 02 | Time: 0m 35s\n",
            "\tTrain Loss: 6.466\n",
            "Epoch: 03 | Time: 0m 35s\n",
            "\tTrain Loss: 6.122\n",
            "Epoch: 04 | Time: 0m 35s\n",
            "\tTrain Loss: 5.835\n",
            "Epoch: 05 | Time: 0m 35s\n",
            "\tTrain Loss: 5.510\n",
            "Epoch: 06 | Time: 0m 35s\n",
            "\tTrain Loss: 5.082\n",
            "Epoch: 07 | Time: 0m 35s\n",
            "\tTrain Loss: 4.611\n",
            "Epoch: 08 | Time: 0m 35s\n",
            "\tTrain Loss: 4.135\n",
            "Epoch: 09 | Time: 0m 35s\n",
            "\tTrain Loss: 3.620\n",
            "Epoch: 10 | Time: 0m 35s\n",
            "\tTrain Loss: 3.068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgitdxhNmeEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff17da8-a83a-4cfc-d09b-9f8592cc9b2e"
      },
      "source": [
        "model.load_state_dict(torch.load('seq2seq-model.pt'))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhx5VBEH1fzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff378314-e926-479b-f8da-d8cca0e9f6c5"
      },
      "source": [
        "test_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f}')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 9.266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWXEL09MQ_k8"
      },
      "source": [
        "# Inference:\n",
        "\n",
        "The trained model is used for generating the headlines.\n",
        "\n",
        "The input news articles are tokenised and passed to the model in evaluation mode. \n",
        "The predicted output sentence is converted from indexes to tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnmcs0jrqP3g"
      },
      "source": [
        "\n",
        "def summarise_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    nlp = spacy.load('en')\n",
        "    tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    print(tokens)\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PitNeKeqm60R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd9ddc9-cc86-4095-db12-25e99407cc3c"
      },
      "source": [
        "example_idx = 12\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['Cleaned_Article']\n",
        "trg = vars(train_data.examples[example_idx])['Cleaned_Headline']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "src1 = \"\"\n",
        "for tok in src:\n",
        "  src1+=(tok)+\" \"\n",
        "print(src1)\n",
        "summarisation, attention = summarise_sentence(src1, TXT, TXT, model, device)\n",
        "\n",
        "print(f'predicted trg = {summarisation}')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['soaring', 'oil', 'sales', 'and', 'budget', 'surplus', 'mean', 'russian', 'debt', 'longer', 'risky', 'investment', 'one', 'the', 'world', 'leading', 'credit', 'rating', 'agencies', 'says', 'standard', 'poor', 'has', 'classed', 'russian', 'bonds', 'investment', 'grade', 'from', 'their', 'former', 'speculative', 'rating', 'russia', 'reputation', 'among', 'investors', 'has', 'been', 'hurt', 'recent', 'months', 'the', 'heavy', 'tax', 'bills', 'and', 'asset', 'seizures', 'imposed', 'companies', 'such', 'oil', 'giant', 'yukos', 'said', 'the', 'solidity', 'government', 'finances', 'outweighed', 'the', 'risk', 'russia', 'now', 'net', 'creditor', 'rather', 'than', 'debtor', 'gold', 'and', 'foreign', 'currency', 'reserves', 'beat', 'its', 'foreign', 'public', 'debt', 'some', 'the', 'other', 'two', 'major', 'ratings', 'agencies', 'fitch', 'and', 'moody', 'have', 'long', 'since', 'upped', 'their', 'rating', 'russia', 'sovereign', 'debt', 'had', 'held', 'back', 'through', 'fear', 'that', 'the', 'government', 'was', 'dragging', 'its', 'feet', 'economic', 'and', 'legal', 'reforms', 'now', 'though', 'has', 'finally', 'followed', 'suit', 'but', 'the', 'agency', 'made', 'clear', 'that', 'the', 'improved', 'rating', 'did', 'not', 'mean', 'that', 'the', 'risks', 'were', 'thing', 'the', 'past', 'instead', 'with', 'russian', 'government', 'coffers', 'brimming', 'with', 'tax', 'revenues', 'from', 'energy', 'sales', 'said', 'the', 'government', 'own', 'debt', 'looking', 'good', 'bet', 'these', 'improvements', 'are', 'significant', 'that', 'they', 'now', 'outweight', 'the', 'serious', 'and', 'growing', 'political', 'risk', 'that', 'continues', 'key', 'ratings', 'constraint', 'russia', 'wrote', 'credit', 'analyst', 'helena', 'hessel', 'the', 'yukos', 'saga', 'the', 'most', 'high', 'profile', 'the', 'political', 'risks', 'which', 'hessel', 'alludes', 'the', 'company', 'founder', 'and', 'chief', 'executive', 'mikhail', 'khodorkovsky', 'jail', 'trial', 'for', 'tax', 'evasion', 'and', 'fraud', 'many', 'believe', 'the', 'real', 'motive', 'for', 'his', 'prosecution', 'that', 'threatened', 'use', 'his', 'wealth', 'set', 'political', 'alternative', 'president', 'vladimir', 'putin', 'his', 'company', 'meanwhile', 'widely', 'believed', 'have', 'fallen', 'victim', 'the', 'kremlin', 'wish', 'get', 'russian', 'energy', 'resources', 'far', 'possible', 'back', 'under', 'state', 'control']\n",
            "trg = ['russia', 'gets', 'investment', 'blessing']\n",
            "soaring oil sales and budget surplus mean russian debt longer risky investment one the world leading credit rating agencies says standard poor has classed russian bonds investment grade from their former speculative rating russia reputation among investors has been hurt recent months the heavy tax bills and asset seizures imposed companies such oil giant yukos said the solidity government finances outweighed the risk russia now net creditor rather than debtor gold and foreign currency reserves beat its foreign public debt some the other two major ratings agencies fitch and moody have long since upped their rating russia sovereign debt had held back through fear that the government was dragging its feet economic and legal reforms now though has finally followed suit but the agency made clear that the improved rating did not mean that the risks were thing the past instead with russian government coffers brimming with tax revenues from energy sales said the government own debt looking good bet these improvements are significant that they now outweight the serious and growing political risk that continues key ratings constraint russia wrote credit analyst helena hessel the yukos saga the most high profile the political risks which hessel alludes the company founder and chief executive mikhail khodorkovsky jail trial for tax evasion and fraud many believe the real motive for his prosecution that threatened use his wealth set political alternative president vladimir putin his company meanwhile widely believed have fallen victim the kremlin wish get russian energy resources far possible back under state control \n",
            "['<sos>', 'soaring', 'oil', 'sales', 'and', 'budget', 'surplus', 'mean', 'russian', 'debt', 'longer', 'risky', 'investment', 'one', 'the', 'world', 'leading', 'credit', 'rating', 'agencies', 'says', 'standard', 'poor', 'has', 'classed', 'russian', 'bonds', 'investment', 'grade', 'from', 'their', 'former', 'speculative', 'rating', 'russia', 'reputation', 'among', 'investors', 'has', 'been', 'hurt', 'recent', 'months', 'the', 'heavy', 'tax', 'bills', 'and', 'asset', 'seizures', 'imposed', 'companies', 'such', 'oil', 'giant', 'yukos', 'said', 'the', 'solidity', 'government', 'finances', 'outweighed', 'the', 'risk', 'russia', 'now', 'net', 'creditor', 'rather', 'than', 'debtor', 'gold', 'and', 'foreign', 'currency', 'reserves', 'beat', 'its', 'foreign', 'public', 'debt', 'some', 'the', 'other', 'two', 'major', 'ratings', 'agencies', 'fitch', 'and', 'moody', 'have', 'long', 'since', 'upped', 'their', 'rating', 'russia', 'sovereign', 'debt', 'had', 'held', 'back', 'through', 'fear', 'that', 'the', 'government', 'was', 'dragging', 'its', 'feet', 'economic', 'and', 'legal', 'reforms', 'now', 'though', 'has', 'finally', 'followed', 'suit', 'but', 'the', 'agency', 'made', 'clear', 'that', 'the', 'improved', 'rating', 'did', 'not', 'mean', 'that', 'the', 'risks', 'were', 'thing', 'the', 'past', 'instead', 'with', 'russian', 'government', 'coffers', 'brimming', 'with', 'tax', 'revenues', 'from', 'energy', 'sales', 'said', 'the', 'government', 'own', 'debt', 'looking', 'good', 'bet', 'these', 'improvements', 'are', 'significant', 'that', 'they', 'now', 'outweight', 'the', 'serious', 'and', 'growing', 'political', 'risk', 'that', 'continues', 'key', 'ratings', 'constraint', 'russia', 'wrote', 'credit', 'analyst', 'helena', 'hessel', 'the', 'yukos', 'saga', 'the', 'most', 'high', 'profile', 'the', 'political', 'risks', 'which', 'hessel', 'alludes', 'the', 'company', 'founder', 'and', 'chief', 'executive', 'mikhail', 'khodorkovsky', 'jail', 'trial', 'for', 'tax', 'evasion', 'and', 'fraud', 'many', 'believe', 'the', 'real', 'motive', 'for', 'his', 'prosecution', 'that', 'threatened', 'use', 'his', 'wealth', 'set', 'political', 'alternative', 'president', 'vladimir', 'putin', 'his', 'company', 'meanwhile', 'widely', 'believed', 'have', 'fallen', 'victim', 'the', 'kremlin', 'wish', 'get', 'russian', 'energy', 'resources', 'far', 'possible', 'back', 'under', 'state', 'control', '<eos>']\n",
            "predicted trg = ['russia', 'direct', 'investment', 'blessing', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDP0Sfu06i36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3046e235-6105-4a3d-ec68-1ad5c8dc84ac"
      },
      "source": [
        "example_idx = 70\n",
        "\n",
        "src1 = vars(val_data.examples[example_idx])['Cleaned_Article']\n",
        "trg1 = vars(val_data.examples[example_idx])['Cleaned_Headline']\n",
        "\n",
        "print(f'src = {src1}')\n",
        "print(f'trg = {trg1}')\n",
        "test_src = \"\"\n",
        "for tok in src1:\n",
        "  test_src+=(tok)+\" \"\n",
        "print(test_src)\n",
        "summary_test, attention_test = summarise_sentence(test_src, TXT, TXT, model, device)\n",
        "\n",
        "print(f'predicted trg = {summary_test}')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['microsoft', 'investigating', 'trojan', 'program', 'that', 'attempts', 'switch', 'off', 'the', 'firm', 'anti', 'spyware', 'software', 'the', 'spyware', 'tool', 'was', 'only', 'released', 'microsoft', 'the', 'last', 'few', 'weeks', 'and', 'has', 'been', 'downloaded', 'six', 'million', 'people', 'stephen', 'toulouse', 'security', 'manager', 'microsoft', 'said', 'the', 'malicious', 'program', 'was', 'called', 'bankash', 'trojan', 'and', 'was', 'being', 'sent', 'mail', 'attachment', 'microsoft', 'said', 'did', 'not', 'believe', 'the', 'program', 'was', 'widespread', 'and', 'recommended', 'users', 'use', 'anti', 'virus', 'program', 'the', 'program', 'attempts', 'disable', 'delete', 'microsoft', 'anti', 'spyware', 'tool', 'and', 'suppress', 'warning', 'messages', 'given', 'users', 'may', 'also', 'try', 'steal', 'online', 'banking', 'passwords', 'other', 'personal', 'information', 'tracking', 'users', 'keystrokes', 'microsoft', 'said', 'statement', 'investigating', 'what', 'called', 'criminal', 'attack', 'its', 'software', 'earlier', 'this', 'week', 'microsoft', 'said', 'would', 'buy', 'anti', 'virus', 'software', 'maker', 'sybari', 'software', 'improve', 'its', 'security', 'its', 'windows', 'and', 'mail', 'software', 'microsoft', 'has', 'said', 'plans', 'offer', 'its', 'own', 'paid', 'for', 'anti', 'virus', 'software', 'but', 'has', 'not', 'yet', 'set', 'date', 'for', 'its', 'release', 'the', 'anti', 'spyware', 'program', 'being', 'targeted', 'currently', 'only', 'beta', 'form', 'and', 'aims', 'help', 'users', 'find', 'and', 'remove', 'spyware', 'programs', 'which', 'monitor', 'internet', 'use', 'causes', 'advert', 'pop', 'ups', 'and', 'slow', 'performance']\n",
            "trg = ['microsoft', 'seeking', 'spyware', 'trojan']\n",
            "microsoft investigating trojan program that attempts switch off the firm anti spyware software the spyware tool was only released microsoft the last few weeks and has been downloaded six million people stephen toulouse security manager microsoft said the malicious program was called bankash trojan and was being sent mail attachment microsoft said did not believe the program was widespread and recommended users use anti virus program the program attempts disable delete microsoft anti spyware tool and suppress warning messages given users may also try steal online banking passwords other personal information tracking users keystrokes microsoft said statement investigating what called criminal attack its software earlier this week microsoft said would buy anti virus software maker sybari software improve its security its windows and mail software microsoft has said plans offer its own paid for anti virus software but has not yet set date for its release the anti spyware program being targeted currently only beta form and aims help users find and remove spyware programs which monitor internet use causes advert pop ups and slow performance \n",
            "['<sos>', 'microsoft', 'investigating', 'trojan', 'program', 'that', 'attempts', 'switch', 'off', 'the', 'firm', 'anti', 'spyware', 'software', 'the', 'spyware', 'tool', 'was', 'only', 'released', 'microsoft', 'the', 'last', 'few', 'weeks', 'and', 'has', 'been', 'downloaded', 'six', 'million', 'people', 'stephen', 'toulouse', 'security', 'manager', 'microsoft', 'said', 'the', 'malicious', 'program', 'was', 'called', 'bankash', 'trojan', 'and', 'was', 'being', 'sent', 'mail', 'attachment', 'microsoft', 'said', 'did', 'not', 'believe', 'the', 'program', 'was', 'widespread', 'and', 'recommended', 'users', 'use', 'anti', 'virus', 'program', 'the', 'program', 'attempts', 'disable', 'delete', 'microsoft', 'anti', 'spyware', 'tool', 'and', 'suppress', 'warning', 'messages', 'given', 'users', 'may', 'also', 'try', 'steal', 'online', 'banking', 'passwords', 'other', 'personal', 'information', 'tracking', 'users', 'keystrokes', 'microsoft', 'said', 'statement', 'investigating', 'what', 'called', 'criminal', 'attack', 'its', 'software', 'earlier', 'this', 'week', 'microsoft', 'said', 'would', 'buy', 'anti', 'virus', 'software', 'maker', 'sybari', 'software', 'improve', 'its', 'security', 'its', 'windows', 'and', 'mail', 'software', 'microsoft', 'has', 'said', 'plans', 'offer', 'its', 'own', 'paid', 'for', 'anti', 'virus', 'software', 'but', 'has', 'not', 'yet', 'set', 'date', 'for', 'its', 'release', 'the', 'anti', 'spyware', 'program', 'being', 'targeted', 'currently', 'only', 'beta', 'form', 'and', 'aims', 'help', 'users', 'find', 'and', 'remove', 'spyware', 'programs', 'which', 'monitor', 'internet', 'use', 'causes', 'advert', 'pop', 'ups', 'and', 'slow', 'performance', '<eos>']\n",
            "predicted trg = ['microsoft', 'seeking', 'safer', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9hOe9UnKjtV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}